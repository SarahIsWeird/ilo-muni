---
layout: "@layouts/Layout.astro"
title: About This Project
---

## Search

## Ranks

## Frequently Asked Questions

### Where is all the data from?

Tons of places- anywhere Toki Pona is spoken (written), so long as there is an associated

#### Discord

Discord makes up the majority of all written Toki Pona. For that matter, [ma pona pi toki pona](https://discord.gg/mapona) makes up the majority of all written Toki Pona on its own. As such, this data is the most important to have a look at- but unfortunately, it is also among the more locked-down platforms on this list. Discord does not offer any native functionality to export messages

#### Facebook

#### Telegram

Conveniently, Telegram offers an "export chat" function directly in its desktop UI, and this dumps every message in the chat that you can see from the start of the chat's existence forward. I found all the communities I could by Telegram's search function and asking around in other communities, [then collected them here after I was done](https://sona.pona.la/wiki/Communities#Telegram).

After that, jan Pensa (@spencjo) helped me out by exporting two particular chats for me, which had data I couldn't get:

- "mi tok e toki pona," a workgroup attemping to get Toki Pona an ISO-639 code. This chat is functionally archived since they succeeded- [toki pona has had an ISO code for over two years!](https://iso639-3.sil.org/code/tok)
- "kulupu pi toki pona-" This chat is public, but up until April 2017 it was configured to only show messages since you joined. Fortunately, jan Pensa had been in this group since March 2016!

The format for Telegram messages is a bit odd in their official exports, and I can't tell what users are bots from the exports alone- but other than that, Telegram was refreshingly easy to add to this list.

#### Reddit

Reddit had functionally removed its own API well before I began this project, so scraping it "officially" would no longer be possible. Similarly, they limited scrollback on all endpoints to only 1000 items, meaning unofficial scraping would have to be done live in order to be sure you fetched everything. I obviously wasn't doing my own live scraping of Reddit, but thanks to [the incredible work of Pushshift, /u/raiderbdev, and /u/Watchful1](https://www.reddit.com/r/pushshift/comments/1akrhg3/separate_dump_files_for_the_top_40k_subreddits/), I was able to fetch at least [/r/tokipona](https://reddit.com/r/tokipona).

On that note: If you have or can create a complete archive of [/r/mi_lon](https://reddit.com/r/mi_lon), [/r/tokiponataso](https://reddit.com/r/tokiponataso), [/r/tokiponaunpa](https://reddit.com/r/tokiponaunpa), [/r/liputenpo](https://reddit.com/r/liputenpo), or any other toki pona communities on Reddit, please let me know!

#### Toki Pona Forums

#### Yahoo! Groups

#### Livejournal

### Will you add more data in the future?

Yes! I'd like to add

### How often will you update the data?

I'm not sure yet! I'd like to update no less than once a year, but doing so two or even four times isn't out of the question. Collecting, parsing, and counting up all of the data is not labor intensive- writing the code to do all that was, but most of that is done.
